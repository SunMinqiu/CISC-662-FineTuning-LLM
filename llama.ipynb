{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "42da4272-da2b-4efc-abf2-260524c921f5",
      "metadata": {
        "id": "42da4272-da2b-4efc-abf2-260524c921f5"
      },
      "source": [
        "# **Setup**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "785cfffe-61b2-44d5-82a0-9a33343b3082",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "785cfffe-61b2-44d5-82a0-9a33343b3082",
        "outputId": "11229761-6839-434b-ca3b-8dddf4d2a68e",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting jupyterlab-nvidia-nsight\n",
            "  Downloading jupyterlab_nvidia_nsight-0.6.0-py3-none-any.whl.metadata (7.5 kB)\n",
            "Collecting docker (from jupyterlab-nvidia-nsight)\n",
            "  Downloading docker-7.1.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting jupyter-server<3,>=2.0.1 (from jupyterlab-nvidia-nsight)\n",
            "  Downloading jupyter_server-2.14.2-py3-none-any.whl.metadata (8.4 kB)\n",
            "Requirement already satisfied: anyio>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=2.0.1->jupyterlab-nvidia-nsight) (3.7.1)\n",
            "Requirement already satisfied: argon2-cffi>=21.1 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=2.0.1->jupyterlab-nvidia-nsight) (23.1.0)\n",
            "Requirement already satisfied: jinja2>=3.0.3 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=2.0.1->jupyterlab-nvidia-nsight) (3.1.4)\n",
            "Collecting jupyter-client>=7.4.4 (from jupyter-server<3,>=2.0.1->jupyterlab-nvidia-nsight)\n",
            "  Downloading jupyter_client-8.6.3-py3-none-any.whl.metadata (8.3 kB)\n",
            "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=2.0.1->jupyterlab-nvidia-nsight) (5.7.2)\n",
            "Collecting jupyter-events>=0.9.0 (from jupyter-server<3,>=2.0.1->jupyterlab-nvidia-nsight)\n",
            "  Downloading jupyter_events-0.10.0-py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting jupyter-server-terminals>=0.4.4 (from jupyter-server<3,>=2.0.1->jupyterlab-nvidia-nsight)\n",
            "  Downloading jupyter_server_terminals-0.5.3-py3-none-any.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: nbconvert>=6.4.4 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=2.0.1->jupyterlab-nvidia-nsight) (7.16.4)\n",
            "Requirement already satisfied: nbformat>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=2.0.1->jupyterlab-nvidia-nsight) (5.10.4)\n",
            "Collecting overrides>=5.0 (from jupyter-server<3,>=2.0.1->jupyterlab-nvidia-nsight)\n",
            "  Downloading overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: packaging>=22.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=2.0.1->jupyterlab-nvidia-nsight) (24.2)\n",
            "Requirement already satisfied: prometheus-client>=0.9 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=2.0.1->jupyterlab-nvidia-nsight) (0.21.1)\n",
            "Requirement already satisfied: pyzmq>=24 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=2.0.1->jupyterlab-nvidia-nsight) (24.0.1)\n",
            "Requirement already satisfied: send2trash>=1.8.2 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=2.0.1->jupyterlab-nvidia-nsight) (1.8.3)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=2.0.1->jupyterlab-nvidia-nsight) (0.18.1)\n",
            "Requirement already satisfied: tornado>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=2.0.1->jupyterlab-nvidia-nsight) (6.3.3)\n",
            "Requirement already satisfied: traitlets>=5.6.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=2.0.1->jupyterlab-nvidia-nsight) (5.7.1)\n",
            "Requirement already satisfied: websocket-client>=1.7 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=2.0.1->jupyterlab-nvidia-nsight) (1.8.0)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from docker->jupyterlab-nvidia-nsight) (2.32.3)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from docker->jupyterlab-nvidia-nsight) (2.2.3)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio>=3.1.0->jupyter-server<3,>=2.0.1->jupyterlab-nvidia-nsight) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio>=3.1.0->jupyter-server<3,>=2.0.1->jupyterlab-nvidia-nsight) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio>=3.1.0->jupyter-server<3,>=2.0.1->jupyterlab-nvidia-nsight) (1.2.2)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.10/dist-packages (from argon2-cffi>=21.1->jupyter-server<3,>=2.0.1->jupyterlab-nvidia-nsight) (21.2.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2>=3.0.3->jupyter-server<3,>=2.0.1->jupyterlab-nvidia-nsight) (3.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from jupyter-client>=7.4.4->jupyter-server<3,>=2.0.1->jupyterlab-nvidia-nsight) (2.8.2)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core!=5.0.*,>=4.12->jupyter-server<3,>=2.0.1->jupyterlab-nvidia-nsight) (4.3.6)\n",
            "Requirement already satisfied: jsonschema>=4.18.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.0.1->jupyterlab-nvidia-nsight) (4.23.0)\n",
            "Collecting python-json-logger>=2.0.4 (from jupyter-events>=0.9.0->jupyter-server<3,>=2.0.1->jupyterlab-nvidia-nsight)\n",
            "  Downloading python_json_logger-2.0.7-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: pyyaml>=5.3 in /usr/local/lib/python3.10/dist-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.0.1->jupyterlab-nvidia-nsight) (6.0.2)\n",
            "Requirement already satisfied: referencing in /usr/local/lib/python3.10/dist-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.0.1->jupyterlab-nvidia-nsight) (0.35.1)\n",
            "Collecting rfc3339-validator (from jupyter-events>=0.9.0->jupyter-server<3,>=2.0.1->jupyterlab-nvidia-nsight)\n",
            "  Downloading rfc3339_validator-0.1.4-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting rfc3986-validator>=0.1.1 (from jupyter-events>=0.9.0->jupyter-server<3,>=2.0.1->jupyterlab-nvidia-nsight)\n",
            "  Downloading rfc3986_validator-0.1.1-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.0.1->jupyterlab-nvidia-nsight) (4.12.3)\n",
            "Requirement already satisfied: bleach!=5.0.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.0.1->jupyterlab-nvidia-nsight) (6.2.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.0.1->jupyterlab-nvidia-nsight) (0.7.1)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.0.1->jupyterlab-nvidia-nsight) (0.3.0)\n",
            "Requirement already satisfied: mistune<4,>=2.0.3 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.0.1->jupyterlab-nvidia-nsight) (3.0.2)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.0.1->jupyterlab-nvidia-nsight) (0.10.1)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.0.1->jupyterlab-nvidia-nsight) (1.5.1)\n",
            "Requirement already satisfied: pygments>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.0.1->jupyterlab-nvidia-nsight) (2.18.0)\n",
            "Requirement already satisfied: tinycss2 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.0.1->jupyterlab-nvidia-nsight) (1.4.0)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.10/dist-packages (from nbformat>=5.3.0->jupyter-server<3,>=2.0.1->jupyterlab-nvidia-nsight) (2.21.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->docker->jupyterlab-nvidia-nsight) (3.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->docker->jupyterlab-nvidia-nsight) (2024.8.30)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.10/dist-packages (from terminado>=0.8.3->jupyter-server<3,>=2.0.1->jupyterlab-nvidia-nsight) (0.7.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach!=5.0.0->nbconvert>=6.4.4->jupyter-server<3,>=2.0.1->jupyterlab-nvidia-nsight) (0.5.1)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=4.18.0->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.0.1->jupyterlab-nvidia-nsight) (24.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=4.18.0->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.0.1->jupyterlab-nvidia-nsight) (2024.10.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=4.18.0->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.0.1->jupyterlab-nvidia-nsight) (0.22.3)\n",
            "Collecting fqdn (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.0.1->jupyterlab-nvidia-nsight)\n",
            "  Downloading fqdn-1.5.1-py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting isoduration (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.0.1->jupyterlab-nvidia-nsight)\n",
            "  Downloading isoduration-20.11.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: jsonpointer>1.13 in /usr/local/lib/python3.10/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.0.1->jupyterlab-nvidia-nsight) (3.0.0)\n",
            "Collecting uri-template (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.0.1->jupyterlab-nvidia-nsight)\n",
            "  Downloading uri_template-1.3.0-py3-none-any.whl.metadata (8.8 kB)\n",
            "Requirement already satisfied: webcolors>=24.6.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.0.1->jupyterlab-nvidia-nsight) (24.11.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->jupyter-client>=7.4.4->jupyter-server<3,>=2.0.1->jupyterlab-nvidia-nsight) (1.16.0)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.0.1->jupyterlab-nvidia-nsight) (1.17.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->nbconvert>=6.4.4->jupyter-server<3,>=2.0.1->jupyterlab-nvidia-nsight) (2.6)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.0.1->jupyterlab-nvidia-nsight) (2.22)\n",
            "Collecting arrow>=0.15.0 (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.0.1->jupyterlab-nvidia-nsight)\n",
            "  Downloading arrow-1.3.0-py3-none-any.whl.metadata (7.5 kB)\n",
            "Collecting types-python-dateutil>=2.8.10 (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.0.1->jupyterlab-nvidia-nsight)\n",
            "  Downloading types_python_dateutil-2.9.0.20241206-py3-none-any.whl.metadata (2.1 kB)\n",
            "Downloading jupyterlab_nvidia_nsight-0.6.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.0/58.0 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jupyter_server-2.14.2-py3-none-any.whl (383 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m383.6/383.6 kB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading docker-7.1.0-py3-none-any.whl (147 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.8/147.8 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jupyter_client-8.6.3-py3-none-any.whl (106 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.1/106.1 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jupyter_events-0.10.0-py3-none-any.whl (18 kB)\n",
            "Downloading jupyter_server_terminals-0.5.3-py3-none-any.whl (13 kB)\n",
            "Downloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
            "Downloading python_json_logger-2.0.7-py3-none-any.whl (8.1 kB)\n",
            "Downloading rfc3986_validator-0.1.1-py2.py3-none-any.whl (4.2 kB)\n",
            "Downloading rfc3339_validator-0.1.4-py2.py3-none-any.whl (3.5 kB)\n",
            "Downloading fqdn-1.5.1-py3-none-any.whl (9.1 kB)\n",
            "Downloading isoduration-20.11.0-py3-none-any.whl (11 kB)\n",
            "Downloading uri_template-1.3.0-py3-none-any.whl (11 kB)\n",
            "Downloading arrow-1.3.0-py3-none-any.whl (66 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.4/66.4 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading types_python_dateutil-2.9.0.20241206-py3-none-any.whl (14 kB)\n",
            "Installing collected packages: uri-template, types-python-dateutil, rfc3986-validator, rfc3339-validator, python-json-logger, overrides, fqdn, jupyter-server-terminals, jupyter-client, docker, arrow, isoduration, jupyter-events, jupyter-server, jupyterlab-nvidia-nsight\n",
            "  Attempting uninstall: jupyter-client\n",
            "    Found existing installation: jupyter-client 6.1.12\n",
            "    Uninstalling jupyter-client-6.1.12:\n",
            "      Successfully uninstalled jupyter-client-6.1.12\n",
            "  Attempting uninstall: jupyter-server\n",
            "    Found existing installation: jupyter-server 1.24.0\n",
            "    Uninstalling jupyter-server-1.24.0:\n",
            "      Successfully uninstalled jupyter-server-1.24.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "notebook 6.5.5 requires jupyter-client<8,>=5.3.4, but you have jupyter-client 8.6.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed arrow-1.3.0 docker-7.1.0 fqdn-1.5.1 isoduration-20.11.0 jupyter-client-8.6.3 jupyter-events-0.10.0 jupyter-server-2.14.2 jupyter-server-terminals-0.5.3 jupyterlab-nvidia-nsight-0.6.0 overrides-7.7.0 python-json-logger-2.0.7 rfc3339-validator-0.1.4 rfc3986-validator-0.1.1 types-python-dateutil-2.9.0.20241206 uri-template-1.3.0\n",
            "Collecting datasets\n",
            "  Downloading datasets-3.1.0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.6)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets)\n",
            "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.9)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.26.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Downloading datasets-3.1.0-py3-none-any.whl (480 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m26.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, fsspec, dill, multiprocess, datasets\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.10.0\n",
            "    Uninstalling fsspec-2024.10.0:\n",
            "      Successfully uninstalled fsspec-2024.10.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.1.0 dill-0.3.8 fsspec-2024.9.0 multiprocess-0.70.16 xxhash-3.5.0\n",
            "Collecting bitsandbytes\n",
            "  Downloading bitsandbytes-0.45.0-py3-none-manylinux_2_24_x86_64.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (2.5.1+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (1.26.4)\n",
            "Requirement already satisfied: typing_extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (4.12.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.16.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (2024.9.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->bitsandbytes) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->bitsandbytes) (3.0.2)\n",
            "Downloading bitsandbytes-0.45.0-py3-none-manylinux_2_24_x86_64.whl (69.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.1/69.1 MB\u001b[0m \u001b[31m25.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: bitsandbytes\n",
            "Successfully installed bitsandbytes-0.45.0\n",
            "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.10/dist-packages (0.45.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (2.5.1+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (1.26.4)\n",
            "Requirement already satisfied: typing_extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (4.12.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.16.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (2024.9.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->bitsandbytes) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->bitsandbytes) (3.0.2)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (1.1.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.26.3)\n",
            "Requirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.5)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.5.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (2024.9.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (4.66.6)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2024.8.30)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (0.26.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2024.9.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.66.6)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2024.8.30)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.46.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.26.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.9.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.8.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.55.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.7)\n",
            "Requirement already satisfied: numpy<2,>=1.21 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Requirement already satisfied: peft in /usr/local/lib/python3.10/dist-packages (0.13.2)\n",
            "Collecting peft\n",
            "  Downloading peft-0.14.0-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from peft) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from peft) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from peft) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from peft) (6.0.2)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from peft) (2.5.1+cu121)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from peft) (4.46.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from peft) (4.66.6)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from peft) (1.1.1)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from peft) (0.4.5)\n",
            "Requirement already satisfied: huggingface-hub>=0.25.0 in /usr/local/lib/python3.10/dist-packages (from peft) (0.26.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.0->peft) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.0->peft) (2024.9.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.0->peft) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.0->peft) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.13.0->peft) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->peft) (2024.9.11)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers->peft) (0.20.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13.0->peft) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.25.0->peft) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.25.0->peft) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.25.0->peft) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.25.0->peft) (2024.8.30)\n",
            "Downloading peft-0.14.0-py3-none-any.whl (374 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m374.8/374.8 kB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: peft\n",
            "  Attempting uninstall: peft\n",
            "    Found existing installation: peft 0.13.2\n",
            "    Uninstalling peft-0.13.2:\n",
            "      Successfully uninstalled peft-0.13.2\n",
            "Successfully installed peft-0.14.0\n",
            "Collecting trl\n",
            "  Downloading trl-0.12.2-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: accelerate>=0.34.0 in /usr/local/lib/python3.10/dist-packages (from trl) (1.1.1)\n",
            "Requirement already satisfied: datasets>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from trl) (3.1.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from trl) (13.9.4)\n",
            "Requirement already satisfied: transformers<4.47.0 in /usr/local/lib/python3.10/dist-packages (from trl) (4.46.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.34.0->trl) (0.26.3)\n",
            "Requirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.34.0->trl) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.34.0->trl) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.34.0->trl) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.34.0->trl) (6.0.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.34.0->trl) (0.4.5)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.34.0->trl) (2.5.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.21.0->trl) (3.16.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.21.0->trl) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.21.0->trl) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets>=2.21.0->trl) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.21.0->trl) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.21.0->trl) (4.66.6)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets>=2.21.0->trl) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.21.0->trl) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets>=2.21.0->trl) (2024.9.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.21.0->trl) (3.11.9)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<4.47.0->trl) (2024.9.11)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers<4.47.0->trl) (0.20.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->trl) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->trl) (2.18.0)\n",
            "Requirement already satisfied: typing-extensions<5.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from rich->trl) (4.12.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.21.0->trl) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.21.0->trl) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.21.0->trl) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.21.0->trl) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.21.0->trl) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.21.0->trl) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.21.0->trl) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.21.0->trl) (1.18.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->trl) (0.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.21.0->trl) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.21.0->trl) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.21.0->trl) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.21.0->trl) (2024.8.30)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate>=0.34.0->trl) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate>=0.34.0->trl) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate>=0.34.0->trl) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.10.0->accelerate>=0.34.0->trl) (1.3.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.21.0->trl) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.21.0->trl) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.21.0->trl) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets>=2.21.0->trl) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate>=0.34.0->trl) (3.0.2)\n",
            "Downloading trl-0.12.2-py3-none-any.whl (365 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m365.7/365.7 kB\u001b[0m \u001b[31m895.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: trl\n",
            "Successfully installed trl-0.12.2\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.10/dist-packages (0.18.7)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.1.43)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb) (4.3.6)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (4.25.5)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.32.3)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.19.0)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb) (1.3.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (75.1.0)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4 in /usr/local/lib/python3.10/dist-packages (from wandb) (4.12.2)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.11)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2024.8.30)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install jupyterlab-nvidia-nsight\n",
        "!pip install datasets\n",
        "!pip install bitsandbytes\n",
        "!pip install --upgrade bitsandbytes\n",
        "!pip install accelerate\n",
        "!pip install huggingface_hub\n",
        "\n",
        "!pip install transformers\n",
        "!pip install matplotlib\n",
        "\n",
        "!pip install peft --upgrade  # Upgrade peft to the latest version\n",
        "!pip install trl\n",
        "!pip install wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "248da905-7709-4d75-98a4-953814806fbc",
      "metadata": {
        "id": "248da905-7709-4d75-98a4-953814806fbc"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import login\n",
        "\n",
        "# I prefer not showing the huggingface access token"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "u4hWC6tQ-K44",
      "metadata": {
        "id": "u4hWC6tQ-K44"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import login\n",
        "\n",
        "# I prefer not showing the huggingface access token"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "JiAxmUgTK0jw",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "JiAxmUgTK0jw",
        "outputId": "6e3fbd2e-fe90-48d0-d4fe-53ad5526ffc2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
          ]
        },
        {
          "data": {
            "application/javascript": "\n        window._wandbApiKey = new Promise((resolve, reject) => {\n            function loadScript(url) {\n            return new Promise(function(resolve, reject) {\n                let newScript = document.createElement(\"script\");\n                newScript.onerror = reject;\n                newScript.onload = resolve;\n                document.body.appendChild(newScript);\n                newScript.src = url;\n            });\n            }\n            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n            const iframe = document.createElement('iframe')\n            iframe.style.cssText = \"width:0;height:0;border:none\"\n            document.body.appendChild(iframe)\n            const handshake = new Postmate({\n                container: iframe,\n                url: 'https://wandb.ai/authorize'\n            });\n            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n            handshake.then(function(child) {\n                child.on('authorize', data => {\n                    clearTimeout(timeout)\n                    resolve(data)\n                });\n            });\n            })\n        });\n    ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import wandb\n",
        "wandb.login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "JSuJ6_mIeqHs",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JSuJ6_mIeqHs",
        "outputId": "8df76830-0e15-4982-8f15-7813c31e72e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mon Dec  9 22:12:11 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  NVIDIA A100-SXM4-40GB          Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   31C    P0              43W / 400W |      2MiB / 40960MiB |      0%      Default |\n",
            "|                                         |                      |             Disabled |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "oWWbjK3ye1NI",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oWWbjK3ye1NI",
        "outputId": "fd85a6e5-71ca-4775-8e5b-461df6a9be26"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.5.1+cu121\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "print(torch.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "59c9d383",
      "metadata": {},
      "outputs": [],
      "source": [
        "# AMD B&B\n",
        "# Clone the github repo\n",
        "!git clone --recurse https://github.com/ROCm/bitsandbytes.git\n",
        "%cd bitsandbytes\n",
        "!git checkout rocm_enabled_multi_backend\n",
        "\n",
        "# Install dependencies\n",
        "!pip install -r requirements-dev.txt\n",
        "\n",
        "# Use -DBNB_ROCM_ARCH to specify target GPU arch\n",
        "!cmake -DBNB_ROCM_ARCH=\"gfx942\" -DCOMPUTE_BACKEND=hip -S .\n",
        "\n",
        "# Compile the project\n",
        "!make\n",
        "\n",
        "# Install\n",
        "!python setup.py install"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c0718f1f-82d0-40cd-9b8d-24a33b4aab28",
      "metadata": {
        "id": "c0718f1f-82d0-40cd-9b8d-24a33b4aab28"
      },
      "source": [
        "# **Train and Evaluate**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "501217c6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "501217c6",
        "outputId": "7aa8f63a-5dc7-4761-ffff-26fc73f6e16d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mon Dec  9 20:15:36 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  NVIDIA A100-SXM4-40GB          Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   33C    P0              45W / 400W |      2MiB / 40960MiB |      0%      Default |\n",
            "|                                         |                      |             Disabled |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9398bfe3-e7aa-4ecc-bc62-1a295263ba30",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "9398bfe3-e7aa-4ecc-bc62-1a295263ba30",
        "outputId": "9ab379e2-13fc-4121-a162-ebae5c2448d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2024-12-09 21:23:19.426668: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2024-12-09 21:23:19.443555: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-12-09 21:23:19.465282: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-12-09 21:23:19.471863: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-12-09 21:23:19.487524: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-12-09 21:23:20.697799: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Using device: cuda\n",
            "Using the latest cached version of the dataset since mosaicml/instruct-v3 couldn't be found on the Hugging Face Hub\n",
            "Found the latest cached dataset configuration 'default' at /content/dataset/mosaicml___instruct-v3/default/0.0.0/d53c69fd0fa37d65a232811cec0a990c1ec3ec8f (last modified on Mon Dec  9 21:09:37 2024).\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:774: UserWarning: `return_dict_in_generate` is NOT set to `True`, but `output_hidden_states` is. When `return_dict_in_generate` is not `True`, `output_hidden_states` is ignored.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_deprecation.py:100: FutureWarning: Deprecated argument(s) used in '__init__': max_seq_length, packing. Will not be supported from version '0.13.0'.\n",
            "\n",
            "Deprecated positional argument(s) used in SFTTrainer, please use the SFTConfig to set these arguments instead.\n",
            "  warnings.warn(message, FutureWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/trl/trainer/sft_trainer.py:212: UserWarning: You passed a `packing` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/trl/trainer/sft_trainer.py:300: UserWarning: You passed a `max_seq_length` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n",
            "  warnings.warn(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmqsun\u001b[0m (\u001b[33mmqsun-university-of-delaware\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.7\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/wandb/run-20241209_212345-32g7f5wl\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mllama1_A\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/mqsun-university-of-delaware/huggingface\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/mqsun-university-of-delaware/huggingface/runs/32g7f5wl\u001b[0m\n",
            "  0% 0/140 [00:00<?, ?it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "{'loss': 2.4913, 'grad_norm': 0.08148863911628723, 'learning_rate': 4e-05, 'epoch': 0.02}\n",
            "  7% 10/140 [00:08<01:34,  1.37it/s]\n",
            "  0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            " 29% 2/7 [00:00<00:00, 12.60it/s]\u001b[A\n",
            " 57% 4/7 [00:00<00:00,  3.57it/s]\u001b[A\n",
            " 71% 5/7 [00:01<00:00,  3.11it/s]\u001b[A\n",
            " 86% 6/7 [00:01<00:00,  2.85it/s]\u001b[A\n",
            "                                    \n",
            "\u001b[A{'eval_loss': 2.6067416667938232, 'eval_runtime': 3.3417, 'eval_samples_per_second': 16.16, 'eval_steps_per_second': 2.095, 'epoch': 0.02}\n",
            "  7% 10/140 [00:11<01:34,  1.37it/s]\n",
            "100% 7/7 [00:02<00:00,  2.67it/s]\u001b[A\n",
            "{'loss': 2.5052, 'grad_norm': 0.08080586791038513, 'learning_rate': 8e-05, 'epoch': 0.04}\n",
            " 14% 20/140 [00:18<01:30,  1.33it/s]\n",
            "  0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            " 29% 2/7 [00:00<00:01,  4.78it/s]\u001b[A\n",
            " 43% 3/7 [00:00<00:01,  3.36it/s]\u001b[A\n",
            " 57% 4/7 [00:01<00:01,  2.91it/s]\u001b[A\n",
            " 71% 5/7 [00:01<00:00,  2.70it/s]\u001b[A\n",
            " 86% 6/7 [00:02<00:00,  2.59it/s]\u001b[A\n",
            "                                    \n",
            "\u001b[A{'eval_loss': 2.5974881649017334, 'eval_runtime': 3.1095, 'eval_samples_per_second': 17.366, 'eval_steps_per_second': 2.251, 'epoch': 0.04}\n",
            " 14% 20/140 [00:22<01:30,  1.33it/s]\n",
            "100% 7/7 [00:02<00:00,  2.49it/s]\u001b[A\n",
            "{'loss': 2.3431, 'grad_norm': 0.12907634675502777, 'learning_rate': 0.00012, 'epoch': 0.05}\n",
            " 21% 30/140 [00:29<01:22,  1.33it/s]\n",
            "  0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            " 29% 2/7 [00:00<00:01,  4.78it/s]\u001b[A\n",
            " 43% 3/7 [00:00<00:01,  3.36it/s]\u001b[A\n",
            " 57% 4/7 [00:01<00:01,  2.91it/s]\u001b[A\n",
            " 71% 5/7 [00:01<00:00,  2.70it/s]\u001b[A\n",
            " 86% 6/7 [00:02<00:00,  2.59it/s]\u001b[A\n",
            "                                    \n",
            "\u001b[A{'eval_loss': 2.575122117996216, 'eval_runtime': 3.0834, 'eval_samples_per_second': 17.513, 'eval_steps_per_second': 2.27, 'epoch': 0.05}\n",
            " 21% 30/140 [00:32<01:22,  1.33it/s]\n",
            "100% 7/7 [00:02<00:00,  2.49it/s]\u001b[A\n",
            "{'loss': 2.5069, 'grad_norm': 0.16183705627918243, 'learning_rate': 0.00016, 'epoch': 0.07}\n",
            " 29% 40/140 [00:39<01:15,  1.33it/s]\n",
            "  0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            " 29% 2/7 [00:00<00:01,  4.76it/s]\u001b[A\n",
            " 43% 3/7 [00:00<00:01,  3.35it/s]\u001b[A\n",
            " 57% 4/7 [00:01<00:01,  2.91it/s]\u001b[A\n",
            " 71% 5/7 [00:01<00:00,  2.70it/s]\u001b[A\n",
            " 86% 6/7 [00:02<00:00,  2.58it/s]\u001b[A\n",
            "                                    \n",
            "\u001b[A{'eval_loss': 2.554314136505127, 'eval_runtime': 3.1033, 'eval_samples_per_second': 17.401, 'eval_steps_per_second': 2.256, 'epoch': 0.07}\n",
            " 29% 40/140 [00:42<01:15,  1.33it/s]\n",
            "100% 7/7 [00:02<00:00,  2.49it/s]\u001b[A\n",
            "{'loss': 2.5066, 'grad_norm': 0.18343022465705872, 'learning_rate': 0.0002, 'epoch': 0.09}\n",
            " 36% 50/140 [00:49<01:07,  1.33it/s]\n",
            "  0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            " 29% 2/7 [00:00<00:01,  4.77it/s]\u001b[A\n",
            " 43% 3/7 [00:00<00:01,  3.36it/s]\u001b[A\n",
            " 57% 4/7 [00:01<00:01,  2.91it/s]\u001b[A\n",
            " 71% 5/7 [00:01<00:00,  2.70it/s]\u001b[A\n",
            " 86% 6/7 [00:02<00:00,  2.58it/s]\u001b[A\n",
            "                                    \n",
            "\u001b[A{'eval_loss': 2.5384206771850586, 'eval_runtime': 3.1095, 'eval_samples_per_second': 17.366, 'eval_steps_per_second': 2.251, 'epoch': 0.09}\n",
            " 36% 50/140 [00:52<01:07,  1.33it/s]\n",
            "100% 7/7 [00:02<00:00,  2.48it/s]\u001b[A\n",
            "                                 \u001b[A/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "{'loss': 2.5669, 'grad_norm': 0.18084615468978882, 'learning_rate': 0.00017777777777777779, 'epoch': 0.11}\n",
            " 43% 60/140 [01:00<01:00,  1.32it/s]\n",
            "  0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            " 29% 2/7 [00:00<00:01,  4.77it/s]\u001b[A\n",
            " 43% 3/7 [00:00<00:01,  3.36it/s]\u001b[A\n",
            " 57% 4/7 [00:01<00:01,  2.91it/s]\u001b[A\n",
            " 71% 5/7 [00:01<00:00,  2.70it/s]\u001b[A\n",
            " 86% 6/7 [00:02<00:00,  2.58it/s]\u001b[A\n",
            "                                    \n",
            "\u001b[A{'eval_loss': 2.523181200027466, 'eval_runtime': 3.1537, 'eval_samples_per_second': 17.123, 'eval_steps_per_second': 2.22, 'epoch': 0.11}\n",
            " 43% 60/140 [01:03<01:00,  1.32it/s]\n",
            "100% 7/7 [00:02<00:00,  2.49it/s]\u001b[A\n",
            "{'loss': 2.4411, 'grad_norm': 0.18854089081287384, 'learning_rate': 0.00015555555555555556, 'epoch': 0.13}\n",
            " 50% 70/140 [01:10<00:52,  1.33it/s]\n",
            "  0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            " 29% 2/7 [00:00<00:01,  4.76it/s]\u001b[A\n",
            " 43% 3/7 [00:00<00:01,  3.36it/s]\u001b[A\n",
            " 57% 4/7 [00:01<00:01,  2.91it/s]\u001b[A\n",
            " 71% 5/7 [00:01<00:00,  2.70it/s]\u001b[A\n",
            " 86% 6/7 [00:02<00:00,  2.58it/s]\u001b[A\n",
            "                                    \n",
            "\u001b[A{'eval_loss': 2.5146403312683105, 'eval_runtime': 3.1144, 'eval_samples_per_second': 17.339, 'eval_steps_per_second': 2.248, 'epoch': 0.13}\n",
            " 50% 70/140 [01:13<00:52,  1.33it/s]\n",
            "100% 7/7 [00:02<00:00,  2.48it/s]\u001b[A\n",
            "{'loss': 2.3087, 'grad_norm': 0.17267414927482605, 'learning_rate': 0.00013333333333333334, 'epoch': 0.14}\n",
            " 57% 80/140 [01:21<00:45,  1.33it/s]\n",
            "  0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            " 29% 2/7 [00:00<00:01,  4.77it/s]\u001b[A\n",
            " 43% 3/7 [00:00<00:01,  3.35it/s]\u001b[A\n",
            " 57% 4/7 [00:01<00:01,  2.91it/s]\u001b[A\n",
            " 71% 5/7 [00:01<00:00,  2.70it/s]\u001b[A\n",
            " 86% 6/7 [00:02<00:00,  2.58it/s]\u001b[A\n",
            "                                    \n",
            "\u001b[A{'eval_loss': 2.505321979522705, 'eval_runtime': 3.1079, 'eval_samples_per_second': 17.375, 'eval_steps_per_second': 2.252, 'epoch': 0.14}\n",
            " 57% 80/140 [01:24<00:45,  1.33it/s]\n",
            "100% 7/7 [00:02<00:00,  2.49it/s]\u001b[A\n",
            "{'loss': 2.3954, 'grad_norm': 0.1846032738685608, 'learning_rate': 0.00011111111111111112, 'epoch': 0.16}\n",
            " 64% 90/140 [01:31<00:37,  1.33it/s]\n",
            "  0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            " 29% 2/7 [00:00<00:01,  4.78it/s]\u001b[A\n",
            " 43% 3/7 [00:00<00:01,  3.36it/s]\u001b[A\n",
            " 57% 4/7 [00:01<00:01,  2.91it/s]\u001b[A\n",
            " 71% 5/7 [00:01<00:00,  2.69it/s]\u001b[A\n",
            " 86% 6/7 [00:02<00:00,  2.58it/s]\u001b[A\n",
            "                                    \n",
            "\u001b[A{'eval_loss': 2.4948573112487793, 'eval_runtime': 3.1138, 'eval_samples_per_second': 17.342, 'eval_steps_per_second': 2.248, 'epoch': 0.16}\n",
            " 64% 90/140 [01:34<00:37,  1.33it/s]\n",
            "100% 7/7 [00:02<00:00,  2.48it/s]\u001b[A\n",
            "{'loss': 2.3893, 'grad_norm': 0.18107213079929352, 'learning_rate': 8.888888888888889e-05, 'epoch': 0.18}\n",
            " 71% 100/140 [01:41<00:30,  1.33it/s]\n",
            "  0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            " 29% 2/7 [00:00<00:01,  4.77it/s]\u001b[A\n",
            " 43% 3/7 [00:00<00:01,  3.36it/s]\u001b[A\n",
            " 57% 4/7 [00:01<00:01,  2.91it/s]\u001b[A\n",
            " 71% 5/7 [00:01<00:00,  2.70it/s]\u001b[A\n",
            " 86% 6/7 [00:02<00:00,  2.58it/s]\u001b[A\n",
            "                                     \n",
            "\u001b[A{'eval_loss': 2.4854304790496826, 'eval_runtime': 3.0917, 'eval_samples_per_second': 17.466, 'eval_steps_per_second': 2.264, 'epoch': 0.18}\n",
            " 71% 100/140 [01:44<00:30,  1.33it/s]\n",
            "100% 7/7 [00:02<00:00,  2.49it/s]\u001b[A\n",
            "                                 \u001b[A/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "{'loss': 2.3793, 'grad_norm': 0.152690589427948, 'learning_rate': 6.666666666666667e-05, 'epoch': 0.2}\n",
            " 79% 110/140 [01:52<00:22,  1.32it/s]\n",
            "  0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            " 29% 2/7 [00:00<00:01,  4.77it/s]\u001b[A\n",
            " 43% 3/7 [00:00<00:01,  3.36it/s]\u001b[A\n",
            " 57% 4/7 [00:01<00:01,  2.91it/s]\u001b[A\n",
            " 71% 5/7 [00:01<00:00,  2.70it/s]\u001b[A\n",
            " 86% 6/7 [00:02<00:00,  2.58it/s]\u001b[A\n",
            "                                     \n",
            "\u001b[A{'eval_loss': 2.4787020683288574, 'eval_runtime': 3.0906, 'eval_samples_per_second': 17.473, 'eval_steps_per_second': 2.265, 'epoch': 0.2}\n",
            " 79% 110/140 [01:55<00:22,  1.32it/s]\n",
            "100% 7/7 [00:02<00:00,  2.49it/s]\u001b[A\n",
            "{'loss': 2.2464, 'grad_norm': 0.2042248249053955, 'learning_rate': 4.4444444444444447e-05, 'epoch': 0.22}\n",
            " 86% 120/140 [02:02<00:15,  1.33it/s]\n",
            "  0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            " 29% 2/7 [00:00<00:01,  4.77it/s]\u001b[A\n",
            " 43% 3/7 [00:00<00:01,  3.36it/s]\u001b[A\n",
            " 57% 4/7 [00:01<00:01,  2.91it/s]\u001b[A\n",
            " 71% 5/7 [00:01<00:00,  2.70it/s]\u001b[A\n",
            " 86% 6/7 [00:02<00:00,  2.58it/s]\u001b[A\n",
            "                                     \n",
            "\u001b[A{'eval_loss': 2.475303888320923, 'eval_runtime': 3.1057, 'eval_samples_per_second': 17.387, 'eval_steps_per_second': 2.254, 'epoch': 0.22}\n",
            " 86% 120/140 [02:05<00:15,  1.33it/s]\n",
            "100% 7/7 [00:02<00:00,  2.49it/s]\u001b[A\n",
            "{'loss': 2.3592, 'grad_norm': 0.1711590588092804, 'learning_rate': 2.2222222222222223e-05, 'epoch': 0.23}\n",
            " 93% 130/140 [02:12<00:07,  1.33it/s]\n",
            "  0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            " 29% 2/7 [00:00<00:01,  4.78it/s]\u001b[A\n",
            " 43% 3/7 [00:00<00:01,  3.36it/s]\u001b[A\n",
            " 57% 4/7 [00:01<00:01,  2.91it/s]\u001b[A\n",
            " 71% 5/7 [00:01<00:00,  2.70it/s]\u001b[A\n",
            " 86% 6/7 [00:02<00:00,  2.58it/s]\u001b[A\n",
            "                                     \n",
            "\u001b[A{'eval_loss': 2.473568916320801, 'eval_runtime': 3.1161, 'eval_samples_per_second': 17.329, 'eval_steps_per_second': 2.246, 'epoch': 0.23}\n",
            " 93% 130/140 [02:15<00:07,  1.33it/s]\n",
            "100% 7/7 [00:02<00:00,  2.48it/s]\u001b[A\n",
            "{'loss': 2.4286, 'grad_norm': 0.16679781675338745, 'learning_rate': 0.0, 'epoch': 0.25}\n",
            "100% 140/140 [02:23<00:00,  1.33it/s]\n",
            "  0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            " 29% 2/7 [00:00<00:01,  4.78it/s]\u001b[A\n",
            " 43% 3/7 [00:00<00:01,  3.36it/s]\u001b[A\n",
            " 57% 4/7 [00:01<00:01,  2.91it/s]\u001b[A\n",
            " 71% 5/7 [00:01<00:00,  2.70it/s]\u001b[A\n",
            " 86% 6/7 [00:02<00:00,  2.58it/s]\u001b[A\n",
            "                                     \n",
            "\u001b[A{'eval_loss': 2.4729983806610107, 'eval_runtime': 3.1095, 'eval_samples_per_second': 17.366, 'eval_steps_per_second': 2.251, 'epoch': 0.25}\n",
            "100% 140/140 [02:26<00:00,  1.33it/s]\n",
            "100% 7/7 [00:02<00:00,  2.49it/s]\u001b[A\n",
            "{'train_runtime': 147.6082, 'train_samples_per_second': 3.768, 'train_steps_per_second': 0.948, 'train_loss': 2.419145897456578, 'epoch': 0.25}\n",
            "100% 140/140 [02:26<00:00,  1.05s/it]\n"
          ]
        }
      ],
      "source": [
        "!python llama1.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "_PofTD_r95KI",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "_PofTD_r95KI",
        "outputId": "ca659c3e-ddf3-4f39-8d67-a13fdd9173c4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2024-12-10 06:40:16.412460: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2024-12-10 06:40:16.429054: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-12-10 06:40:16.449935: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-12-10 06:40:16.456254: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-12-10 06:40:16.471564: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-12-10 06:40:17.677117: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Using device: cuda\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:774: UserWarning: `return_dict_in_generate` is NOT set to `True`, but `output_hidden_states` is. When `return_dict_in_generate` is not `True`, `output_hidden_states` is ignored.\n",
            "  warnings.warn(\n",
            "Loading checkpoint shards: 100% 4/4 [00:09<00:00,  2.34s/it]\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_deprecation.py:100: FutureWarning: Deprecated argument(s) used in '__init__': max_seq_length, packing. Will not be supported from version '0.13.0'.\n",
            "\n",
            "Deprecated positional argument(s) used in SFTTrainer, please use the SFTConfig to set these arguments instead.\n",
            "  warnings.warn(message, FutureWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/trl/trainer/sft_trainer.py:212: UserWarning: You passed a `packing` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/trl/trainer/sft_trainer.py:300: UserWarning: You passed a `max_seq_length` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n",
            "  warnings.warn(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmqsun\u001b[0m (\u001b[33mmqsun-university-of-delaware\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.7\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/wandb/run-20241210_064038-gyshs3mo\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mllama_Colab\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/mqsun-university-of-delaware/huggingface\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/mqsun-university-of-delaware/huggingface/runs/gyshs3mo\u001b[0m\n",
            "  0% 0/140 [00:00<?, ?it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "{'loss': 2.2216, 'grad_norm': 0.05590183660387993, 'learning_rate': 4e-05, 'epoch': 0.02}\n",
            "{'loss': 2.1524, 'grad_norm': 0.09397891163825989, 'learning_rate': 8e-05, 'epoch': 0.04}\n",
            "{'loss': 2.1029, 'grad_norm': 0.1399650126695633, 'learning_rate': 0.00012, 'epoch': 0.05}\n",
            "{'loss': 2.0701, 'grad_norm': 0.15606212615966797, 'learning_rate': 0.00016, 'epoch': 0.07}\n",
            "{'loss': 2.0922, 'grad_norm': 0.18145129084587097, 'learning_rate': 0.0002, 'epoch': 0.09}\n",
            " 36% 50/140 [02:34<04:36,  3.08s/it]\n",
            "config.json: 100% 826/826 [00:00<00:00, 2.76MB/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "{'loss': 2.0797, 'grad_norm': 0.1786281168460846, 'learning_rate': 0.00017777777777777779, 'epoch': 0.11}\n",
            "{'loss': 2.0921, 'grad_norm': 0.13436725735664368, 'learning_rate': 0.00015555555555555556, 'epoch': 0.13}\n",
            "{'loss': 2.0409, 'grad_norm': 0.12999288737773895, 'learning_rate': 0.00013333333333333334, 'epoch': 0.14}\n",
            "{'loss': 1.9743, 'grad_norm': 0.15097059309482574, 'learning_rate': 0.00011111111111111112, 'epoch': 0.16}\n",
            "{'loss': 2.0447, 'grad_norm': 0.11662708967924118, 'learning_rate': 8.888888888888889e-05, 'epoch': 0.18}\n",
            " 71% 100/140 [05:10<02:02,  3.07s/it]/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "{'loss': 2.0265, 'grad_norm': 0.14921174943447113, 'learning_rate': 6.666666666666667e-05, 'epoch': 0.2}\n",
            "{'loss': 1.9382, 'grad_norm': 0.15790651738643646, 'learning_rate': 4.4444444444444447e-05, 'epoch': 0.22}\n",
            "{'loss': 2.0844, 'grad_norm': 0.177485853433609, 'learning_rate': 2.2222222222222223e-05, 'epoch': 0.23}\n",
            "{'loss': 2.0658, 'grad_norm': 0.14447717368602753, 'learning_rate': 0.0, 'epoch': 0.25}\n",
            "{'train_runtime': 436.9902, 'train_samples_per_second': 1.273, 'train_steps_per_second': 0.32, 'train_loss': 2.070413534981864, 'epoch': 0.25}\n",
            "100% 140/140 [07:15<00:00,  3.11s/it]\n"
          ]
        }
      ],
      "source": [
        "!python llama.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d4a0f6a5-e4e0-4f22-b8bc-62537fb0b42f",
      "metadata": {
        "id": "d4a0f6a5-e4e0-4f22-b8bc-62537fb0b42f"
      },
      "outputs": [],
      "source": [
        "!export CUDA_VISIBLE_DEVICES=0,1\n",
        "!torchrun --standalone --nproc_per_node=2 llama.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "63f12d51",
      "metadata": {
        "id": "63f12d51"
      },
      "outputs": [],
      "source": [
        "# Installing nsight-systems-2022.4.1 & nsight-compute-2022.1.1\n",
        "!apt-get update -y && \\\n",
        "     DEBIAN_FRONTEND=noninteractive apt-get install -y --no-install-recommends \\\n",
        "         apt-transport-https \\\n",
        "         ca-certificates \\\n",
        "         gnupg \\\n",
        "         wget && \\\n",
        "     rm -rf /var/lib/apt/lists/*\n",
        "!wget -qO - https://developer.download.nvidia.com/devtools/repos/ubuntu2004/amd64/nvidia.pub | apt-key add - && \\\n",
        "     echo \"deb https://developer.download.nvidia.com/devtools/repos/ubuntu2004/amd64/ /\" >> /etc/apt/sources.list.d/nsight.list && \\\n",
        "     apt-get update -y && \\\n",
        "     DEBIAN_FRONTEND=noninteractive apt-get install -y --no-install-recommends \\\n",
        "         nsight-systems-2022.1.1 nsight-compute-2022.1.1 && \\\n",
        "     rm -rf /var/lib/apt/lists/*\n",
        "\n",
        "# setting environment variable path\n",
        "import os\n",
        "os.environ[\"PATH\"] = \"/usr/local/bin\" + os.pathsep + os.getenv(\"PATH\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "36be9c19",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "36be9c19",
        "outputId": "72b90140-4a5c-4cc3-9bb0-8133175ca1b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==PROF== Target process 27886 terminated before first instrumented API call.\n",
            "==PROF== Target process 27906 terminated before first instrumented API call.\n",
            "2024-12-09 23:33:44.915248: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2024-12-09 23:33:44.933731: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-12-09 23:33:44.954816: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-12-09 23:33:44.961201: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-12-09 23:33:44.976622: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "==PROF== Target process 27907 terminated before first instrumented API call.\n",
            "2024-12-09 23:33:46.166720: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "==PROF== Target process 27908 terminated before first instrumented API call.\n",
            "==PROF== Target process 27909 terminated before first instrumented API call.\n",
            "==PROF== Target process 27910 terminated before first instrumented API call.\n",
            "==PROF== Target process 27911 terminated before first instrumented API call.\n",
            "==PROF== Target process 27912 terminated before first instrumented API call.\n",
            "==PROF== Connected to process 27885 (/usr/bin/python3.10)\n",
            "==PROF== Target process 27927 terminated before first instrumented API call.\n",
            "Using device: cuda\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:774: UserWarning: `return_dict_in_generate` is NOT set to `True`, but `output_hidden_states` is. When `return_dict_in_generate` is not `True`, `output_hidden_states` is ignored.\n",
            "  warnings.warn(\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "==PROF== Profiling \"kQuantizeBlockwise\": 0%....50%....100% - 10 passes\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "==PROF== Target process 30444 terminated before first instrumented API call.\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_deprecation.py:100: FutureWarning: Deprecated argument(s) used in '__init__': max_seq_length, packing. Will not be supported from version '0.13.0'.\n",
            "\n",
            "Deprecated positional argument(s) used in SFTTrainer, please use the SFTConfig to set these arguments instead.\n",
            "  warnings.warn(message, FutureWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/trl/trainer/sft_trainer.py:212: UserWarning: You passed a `packing` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/trl/trainer/sft_trainer.py:300: UserWarning: You passed a `max_seq_length` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n",
            "  warnings.warn(\n",
            "==PROF== Target process 30445 terminated before first instrumented API call.\n",
            "max_steps is given, it will override any value given in num_train_epochs\n",
            "/usr/local/lib/python3.10/dist-packages/trl/trainer/sft_trainer.py:428: UserWarning: You passed `packing=True` to the SFTTrainer/SFTConfig, and you are training your model with `max_steps` strategy. The dataset will be iterated until the `max_steps` are reached.\n",
            "  warnings.warn(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
            "==PROF== Target process 30453 terminated before first instrumented API call.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmqsun\u001b[0m (\u001b[33mmqsun-university-of-delaware\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.7\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/wandb/run-20241209_233443-g8q5e310\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mllama_1\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/mqsun-university-of-delaware/huggingface\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/mqsun-university-of-delaware/huggingface/runs/g8q5e310\u001b[0m\n",
            "  0% 0/10 [00:00<?, ?it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            " 50% 5/10 [00:06<00:04,  1.02it/s]\n",
            "  0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            " 29% 2/7 [00:00<00:00,  9.12it/s]\u001b[A\n",
            " 43% 3/7 [00:00<00:00,  4.27it/s]\u001b[A\n",
            " 57% 4/7 [00:01<00:00,  3.41it/s]\u001b[A\n",
            " 71% 5/7 [00:01<00:00,  2.84it/s]\u001b[A\n",
            " 86% 6/7 [00:01<00:00,  2.73it/s]\u001b[A==PROF== Target process 30643 terminated before first instrumented API call.\n",
            "==PROF== Target process 30649 terminated before first instrumented API call.\n",
            "==PROF== Target process 30644 terminated before first instrumented API call.\n",
            "==PROF== Target process 30648 terminated before first instrumented API call.\n",
            "==PROF== Target process 30645 terminated before first instrumented API call.\n",
            "==PROF== Target process 30647 terminated before first instrumented API call.\n",
            "==PROF== Target process 30646 terminated before first instrumented API call.\n",
            "==PROF== Target process 30642 terminated before first instrumented API call.\n",
            "\n",
            "                                  \n",
            "\u001b[A{'eval_loss': 2.592244863510132, 'eval_runtime': 3.4239, 'eval_samples_per_second': 15.772, 'eval_steps_per_second': 2.044, 'epoch': 0.01}\n",
            " 50% 5/10 [00:09<00:04,  1.02it/s]\n",
            "100% 7/7 [00:02<00:00,  2.24it/s]\u001b[A\n",
            "                                 \u001b[A/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "100% 10/10 [00:14<00:00,  1.09s/it]\n",
            "  0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            " 29% 2/7 [00:00<00:01,  4.85it/s]\u001b[A\n",
            " 43% 3/7 [00:00<00:01,  3.40it/s]\u001b[A\n",
            " 57% 4/7 [00:01<00:01,  2.94it/s]\u001b[A\n",
            " 71% 5/7 [00:01<00:00,  2.71it/s]\u001b[A\n",
            " 86% 6/7 [00:02<00:00,  2.59it/s]\u001b[A==PROF== Target process 30713 terminated before first instrumented API call.\n",
            "==PROF== Target process 30712 terminated before first instrumented API call.\n",
            "==PROF== Target process 30708 terminated before first instrumented API call.\n",
            "==PROF== Target process 30709 terminated before first instrumented API call.\n",
            "==PROF== Target process 30715 terminated before first instrumented API call.\n",
            "==PROF== Target process 30710 terminated before first instrumented API call.\n",
            "==PROF== Target process 30714 terminated before first instrumented API call.\n",
            "==PROF== Target process 30711 terminated before first instrumented API call.\n",
            "\n",
            "                                   \n",
            "\u001b[A{'eval_loss': 2.587092161178589, 'eval_runtime': 3.1768, 'eval_samples_per_second': 16.998, 'eval_steps_per_second': 2.203, 'epoch': 0.02}\n",
            "100% 10/10 [00:17<00:00,  1.09s/it]\n",
            "100% 7/7 [00:02<00:00,  2.35it/s]\u001b[A\n",
            "{'train_runtime': 20.011, 'train_samples_per_second': 1.999, 'train_steps_per_second': 0.5, 'train_loss': 2.4887411117553713, 'epoch': 0.02}\n",
            "100% 10/10 [00:18<00:00,  1.86s/it]\n",
            "==PROF== Target process 30479 terminated before first instrumented API call.\n",
            "==PROF== Target process 30491 terminated before first instrumented API call.\n",
            "==PROF== Target process 30543 terminated before first instrumented API call.\n",
            "==PROF== Target process 30507 terminated before first instrumented API call.\n",
            "==PROF== Target process 30519 terminated before first instrumented API call.\n",
            "==PROF== Target process 30531 terminated before first instrumented API call.\n",
            "==PROF== Target process 30567 terminated before first instrumented API call.\n",
            "==PROF== Target process 30555 terminated before first instrumented API call.\n",
            "==PROF== Disconnected from process 27885\n",
            "==PROF== Report: /content/llama1_Quan.ncu-rep\n"
          ]
        }
      ],
      "source": [
        "!ncu --device 0 --target-processes all -k regex:kQuantizeBlockwise -o llama1_Quan.ncu-rep python llama1.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1d6afac6",
      "metadata": {
        "id": "1d6afac6"
      },
      "outputs": [],
      "source": [
        "\"!nsys profile --trace=cuda,osrt,mpi,openacc -o analysis python llama.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "gEPn1ep1slfv",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gEPn1ep1slfv",
        "outputId": "a1bb636e-e20f-4029-bfa2-b8dfdcb785e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==PROF== Target process 61841 terminated before first instrumented API call.\n",
            "==PROF== Target process 61863 terminated before first instrumented API call.\n",
            "==PROF== Target process 61864 terminated before first instrumented API call.\n",
            "2024-12-09 23:52:52.104995: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2024-12-09 23:52:52.123818: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-12-09 23:52:52.145396: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-12-09 23:52:52.151892: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-12-09 23:52:52.167118: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "==PROF== Target process 61865 terminated before first instrumented API call.\n",
            "2024-12-09 23:52:53.376034: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "==PROF== Target process 61866 terminated before first instrumented API call.\n",
            "==PROF== Target process 61867 terminated before first instrumented API call.\n",
            "==PROF== Target process 61868 terminated before first instrumented API call.\n",
            "==PROF== Target process 61869 terminated before first instrumented API call.\n",
            "==PROF== Connected to process 61840 (/usr/bin/python3.10)\n",
            "==PROF== Target process 61882 terminated before first instrumented API call.\n",
            "Using device: cuda\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:774: UserWarning: `return_dict_in_generate` is NOT set to `True`, but `output_hidden_states` is. When `return_dict_in_generate` is not `True`, `output_hidden_states` is ignored.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "==PROF== Target process 61985 terminated before first instrumented API call.\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_deprecation.py:100: FutureWarning: Deprecated argument(s) used in '__init__': max_seq_length, packing. Will not be supported from version '0.13.0'.\n",
            "\n",
            "Deprecated positional argument(s) used in SFTTrainer, please use the SFTConfig to set these arguments instead.\n",
            "  warnings.warn(message, FutureWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/trl/trainer/sft_trainer.py:212: UserWarning: You passed a `packing` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/trl/trainer/sft_trainer.py:300: UserWarning: You passed a `max_seq_length` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n",
            "  warnings.warn(\n",
            "==PROF== Target process 61986 terminated before first instrumented API call.\n",
            "max_steps is given, it will override any value given in num_train_epochs\n",
            "/usr/local/lib/python3.10/dist-packages/trl/trainer/sft_trainer.py:428: UserWarning: You passed `packing=True` to the SFTTrainer/SFTConfig, and you are training your model with `max_steps` strategy. The dataset will be iterated until the `max_steps` are reached.\n",
            "  warnings.warn(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
            "==PROF== Target process 61994 terminated before first instrumented API call.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmqsun\u001b[0m (\u001b[33mmqsun-university-of-delaware\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.7\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/wandb/run-20241209_235309-dmjrevgi\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mllama_1\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/mqsun-university-of-delaware/huggingface\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/mqsun-university-of-delaware/huggingface/runs/dmjrevgi\u001b[0m\n",
            "  0% 0/1 [00:00<?, ?it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "100% 1/1 [00:02<00:00,  2.89s/it]\n",
            "  0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            " 29% 2/7 [00:00<00:00, 11.65it/s]\u001b[A\n",
            " 57% 4/7 [00:01<00:00,  3.53it/s]\u001b[A\n",
            " 71% 5/7 [00:01<00:00,  3.08it/s]\u001b[A\n",
            " 86% 6/7 [00:01<00:00,  2.84it/s]\u001b[A==PROF== Target process 62171 terminated before first instrumented API call.\n",
            "==PROF== Target process 62172 terminated before first instrumented API call.\n",
            "==PROF== Target process 62178 terminated before first instrumented API call.\n",
            "==PROF== Target process 62173 terminated before first instrumented API call.\n",
            "==PROF== Target process 62177 terminated before first instrumented API call.\n",
            "==PROF== Target process 62174 terminated before first instrumented API call.\n",
            "==PROF== Target process 62176 terminated before first instrumented API call.\n",
            "==PROF== Target process 62175 terminated before first instrumented API call.\n",
            "\n",
            "                                 \n",
            "\u001b[A{'eval_loss': 2.60024356842041, 'eval_runtime': 3.2153, 'eval_samples_per_second': 16.795, 'eval_steps_per_second': 2.177, 'epoch': 0.0}\n",
            "100% 1/1 [00:06<00:00,  2.89s/it]\n",
            "100% 7/7 [00:02<00:00,  2.29it/s]\u001b[A\n",
            "{'train_runtime': 8.5452, 'train_samples_per_second': 0.117, 'train_steps_per_second': 0.117, 'train_loss': 2.9274370670318604, 'epoch': 0.0}\n",
            "100% 1/1 [00:07<00:00,  7.06s/it]\n",
            "==PROF== Target process 62026 terminated before first instrumented API call.\n",
            "==PROF== Target process 62110 terminated before first instrumented API call.\n",
            "==PROF== Target process 62086 terminated before first instrumented API call.\n",
            "==PROF== Target process 62098 terminated before first instrumented API call.\n",
            "==PROF== Target process 62062 terminated before first instrumented API call.\n",
            "==PROF== Target process 62074 terminated before first instrumented API call.\n",
            "==PROF== Target process 62038 terminated before first instrumented API call.\n",
            "==PROF== Target process 62050 terminated before first instrumented API call.\n",
            "==PROF== Disconnected from process 61840\n",
            "==WARNING== No kernels were profiled.\n"
          ]
        }
      ],
      "source": [
        "!ncu --device 0 --target-processes all -k -o llama2.ncu-rep python llama1.py"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
